{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6w3gstppWmOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfdfcc10-fe99-4c31-80a0-f312ca3b1eba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-9-2105605498.py:7: DtypeWarning: Columns (50,52,53,54,55,56,57,59,61,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  accident_data = pd.read_csv(file_path, encoding='utf-8')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 375457 entries, 0 to 375456\n",
            "Data columns (total 92 columns):\n",
            " #   Column        Non-Null Count   Dtype  \n",
            "---  ------        --------------   -----  \n",
            " 0   STATE         375457 non-null  int64  \n",
            " 1   ST_CASE       375457 non-null  int64  \n",
            " 2   VE_TOTAL      375457 non-null  int64  \n",
            " 3   VE_FORMS      375457 non-null  int64  \n",
            " 4   PVH_INVL      375457 non-null  int64  \n",
            " 5   PEDS          375457 non-null  int64  \n",
            " 6   PERNOTMVIT    375457 non-null  int64  \n",
            " 7   PERMVIT       375457 non-null  int64  \n",
            " 8   PERSONS       375457 non-null  int64  \n",
            " 9   COUNTY        375457 non-null  int64  \n",
            " 10  CITY          375457 non-null  int64  \n",
            " 11  DAY           375457 non-null  int64  \n",
            " 12  MONTH         375457 non-null  int64  \n",
            " 13  YEAR          375457 non-null  int64  \n",
            " 14  DAY_WEEK      375457 non-null  int64  \n",
            " 15  HOUR          375457 non-null  int64  \n",
            " 16  MINUTE        375457 non-null  int64  \n",
            " 17  NHS           375457 non-null  int64  \n",
            " 18  ROAD_FNC      91264 non-null   float64\n",
            " 19  ROUTE         375457 non-null  int64  \n",
            " 20  TWAY_ID       375457 non-null  object \n",
            " 21  TWAY_ID2      97030 non-null   object \n",
            " 22  MILEPT        375457 non-null  int64  \n",
            " 23  LATITUDE      375457 non-null  float64\n",
            " 24  LONGITUD      375457 non-null  float64\n",
            " 25  SP_JUR        375457 non-null  int64  \n",
            " 26  HARM_EV       375457 non-null  int64  \n",
            " 27  MAN_COLL      375457 non-null  int64  \n",
            " 28  RELJCT1       375457 non-null  int64  \n",
            " 29  RELJCT2       375457 non-null  int64  \n",
            " 30  TYP_INT       375457 non-null  int64  \n",
            " 31  WRK_ZONE      375457 non-null  int64  \n",
            " 32  REL_ROAD      375457 non-null  int64  \n",
            " 33  LGT_COND      375457 non-null  int64  \n",
            " 34  WEATHER1      260516 non-null  float64\n",
            " 35  WEATHER2      260516 non-null  float64\n",
            " 36  WEATHER       375457 non-null  int64  \n",
            " 37  SCH_BUS       375457 non-null  int64  \n",
            " 38  RAIL          375457 non-null  object \n",
            " 39  NOT_HOUR      375457 non-null  int64  \n",
            " 40  NOT_MIN       375457 non-null  int64  \n",
            " 41  ARR_HOUR      375457 non-null  int64  \n",
            " 42  ARR_MIN       375457 non-null  int64  \n",
            " 43  HOSP_HR       375457 non-null  int64  \n",
            " 44  HOSP_MN       375457 non-null  int64  \n",
            " 45  CF1           260516 non-null  float64\n",
            " 46  CF2           260516 non-null  float64\n",
            " 47  CF3           260516 non-null  float64\n",
            " 48  FATALS        375457 non-null  int64  \n",
            " 49  DRUNK_DR      296451 non-null  float64\n",
            " 50  STATENAME     284193 non-null  object \n",
            " 51  DAYNAME       284193 non-null  float64\n",
            " 52  MONTHNAME     284193 non-null  object \n",
            " 53  DAY_WEEKNAME  284193 non-null  object \n",
            " 54  HOURNAME      284193 non-null  object \n",
            " 55  MINUTENAME    284193 non-null  object \n",
            " 56  NHSNAME       284193 non-null  object \n",
            " 57  ROUTENAME     284193 non-null  object \n",
            " 58  RUR_URB       284193 non-null  float64\n",
            " 59  RUR_URBNAME   284193 non-null  object \n",
            " 60  FUNC_SYS      284193 non-null  float64\n",
            " 61  FUNC_SYSNAME  284193 non-null  object \n",
            " 62  RD_OWNER      284193 non-null  float64\n",
            " 63  RD_OWNERNAME  284193 non-null  object \n",
            " 64  MILEPTNAME    214300 non-null  object \n",
            " 65  LATITUDENAME  284193 non-null  object \n",
            " 66  LONGITUDNAME  284193 non-null  object \n",
            " 67  SP_JURNAME    284193 non-null  object \n",
            " 68  HARM_EVNAME   284193 non-null  object \n",
            " 69  MAN_COLLNAME  284193 non-null  object \n",
            " 70  RELJCT1NAME   284193 non-null  object \n",
            " 71  RELJCT2NAME   284193 non-null  object \n",
            " 72  TYP_INTNAME   284193 non-null  object \n",
            " 73  WRK_ZONENAME  5980 non-null    object \n",
            " 74  REL_ROADNAME  284193 non-null  object \n",
            " 75  LGT_CONDNAME  284193 non-null  object \n",
            " 76  WEATHER1NAME  169252 non-null  object \n",
            " 77  WEATHER2NAME  169252 non-null  object \n",
            " 78  WEATHERNAME   284193 non-null  object \n",
            " 79  SCH_BUSNAME   284193 non-null  object \n",
            " 80  RAILNAME      284193 non-null  object \n",
            " 81  NOT_HOURNAME  284193 non-null  object \n",
            " 82  NOT_MINNAME   284193 non-null  object \n",
            " 83  ARR_HOURNAME  284193 non-null  object \n",
            " 84  ARR_MINNAME   284193 non-null  object \n",
            " 85  HOSP_HRNAME   284193 non-null  object \n",
            " 86  HOSP_MNNAME   284193 non-null  object \n",
            " 87  CF1NAME       12228 non-null   object \n",
            " 88  CF2NAME       2132 non-null    object \n",
            " 89  CF3NAME       1217 non-null    object \n",
            " 90  COUNTYNAME    251655 non-null  object \n",
            " 91  CITYNAME      251655 non-null  object \n",
            "dtypes: float64(13), int64(38), object(41)\n",
            "memory usage: 263.5+ MB\n",
            "None\n",
            "First 5 rows of the dataset:\n",
            "   STATE  ST_CASE  VE_TOTAL  VE_FORMS  PVH_INVL  PEDS  PERNOTMVIT  PERMVIT  \\\n",
            "0      1    10001         1         1         0     0           0        2   \n",
            "1      1    10002         2         1         1     0           0        1   \n",
            "2      1    10003         1         1         0     0           0        6   \n",
            "3      1    10004         2         2         0     0           0        5   \n",
            "4      1    10005         1         1         0     0           0        1   \n",
            "\n",
            "   PERSONS  COUNTY  ...  NOT_MINNAME  ARR_HOURNAME  ARR_MINNAME  HOSP_HRNAME  \\\n",
            "0        2      81  ...          NaN           NaN          NaN          NaN   \n",
            "1        1      83  ...          NaN           NaN          NaN          NaN   \n",
            "2        6     105  ...          NaN           NaN          NaN          NaN   \n",
            "3        5      81  ...          NaN           NaN          NaN          NaN   \n",
            "4        1      77  ...          NaN           NaN          NaN          NaN   \n",
            "\n",
            "   HOSP_MNNAME  CF1NAME  CF2NAME  CF3NAME  COUNTYNAME  CITYNAME  \n",
            "0          NaN      NaN      NaN      NaN         NaN       NaN  \n",
            "1          NaN      NaN      NaN      NaN         NaN       NaN  \n",
            "2          NaN      NaN      NaN      NaN         NaN       NaN  \n",
            "3          NaN      NaN      NaN      NaN         NaN       NaN  \n",
            "4          NaN      NaN      NaN      NaN         NaN       NaN  \n",
            "\n",
            "[5 rows x 92 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# File path to the dataset\n",
        "file_path = 'FARS_all_years_combined.csv'\n",
        "\n",
        "\n",
        "accident_data = pd.read_csv(file_path, encoding='utf-8')\n",
        "# Display basic information about the dataset\n",
        "print(\"Dataset Information:\")\n",
        "print(accident_data.info())\n",
        "\n",
        "# Display the first few rows\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(accident_data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "# Step 2: Preprocessing - Drop rows with missing values in relevant columns\n",
        "columns_to_use = ['LATITUDE', 'LONGITUD', 'HOUR', 'WEATHERNAME', 'FATALS']\n",
        "#accident_data = accident_data[columns_to_use].dropna()\n",
        "\n",
        "# Step 3: Define features (X) and target variable (y)\n",
        "X = accident_data[['LATITUDE', 'LONGITUD', 'HOUR', 'WEATHERNAME']]\n",
        "y = accident_data['FATALS']\n",
        "\n",
        "# Step 4: Preprocessing - Handle categorical data and scaling\n",
        "categorical_features = ['WEATHERNAME']\n",
        "numerical_features = ['LATITUDE', 'LONGITUD', 'HOUR']\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ]\n",
        ")\n",
        "# Step 5: Save the cleaned dataset\n",
        "accident_data.to_csv(\"cleaned_data\", index=False)\n",
        "\n",
        "# Step 5: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 6: Create a pipeline with preprocessing and regression model\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# Step 7: Train the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Step 8: Make predictions\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Step 9: Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"Predicted Number of Fatalities:\")\n",
        "print(y_pred)\n",
        "print(\"Model Evaluation:\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "# Step 10: Save the trained mode\n",
        "import joblib\n",
        "model_file_path = 'regression_model.pkl'\n",
        "joblib.dump(pipeline, model_file_path)\n",
        "print(f\"Trained model saved to {model_file_path}\")\n"
      ],
      "metadata": {
        "id": "9TXE_dIuWmrU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f3875fe-6b6f-4e46-86ef-4b90e47d7b98"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Number of Fatalities:\n",
            "[1.08555444 1.08691475 1.0899397  ... 1.08500317 1.08874924 1.09597315]\n",
            "Model Evaluation:\n",
            "Mean Squared Error: 0.12565506690348813\n",
            "R-squared: 0.0005103918652263895\n",
            "Trained model saved to regression_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Step 2: Preprocessing - Drop rows with missing values in relevant columns\n",
        "columns_to_use = ['LATITUDE', 'LONGITUD', 'HOUR', 'WEATHERNAME', 'FATALS']\n",
        "accident_data = accident_data[columns_to_use].dropna()\n",
        "\n",
        "# Step 3: Define features (X) and target variables (y_latitude, y_longitude)\n",
        "X = accident_data[['HOUR', 'WEATHERNAME', 'FATALS']]\n",
        "y_latitude = accident_data['LATITUDE']\n",
        "y_longitude = accident_data['LONGITUD']\n",
        "\n",
        "# Step 4: Preprocessing - Handle categorical data and scaling\n",
        "categorical_features = ['WEATHERNAME']\n",
        "numerical_features = ['HOUR', 'FATALS']\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Step 5: Split data into training and testing sets\n",
        "X_train, X_test, y_lat_train, y_lat_test = train_test_split(X, y_latitude, test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_lon_train, y_lon_test = train_test_split(X, y_longitude, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 6: Create pipelines for both latitude and longitude\n",
        "latitude_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "longitude_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# Step 7: Train the models\n",
        "latitude_pipeline.fit(X_train, y_lat_train)\n",
        "longitude_pipeline.fit(X_train, y_lon_train)\n",
        "\n",
        "# Step 8: Make predictions\n",
        "y_lat_pred = latitude_pipeline.predict(X_test)\n",
        "y_lon_pred = longitude_pipeline.predict(X_test)\n",
        "\n",
        "# Step 9: Evaluate the models\n",
        "lat_mse = mean_squared_error(y_lat_test, y_lat_pred)\n",
        "lat_r2 = r2_score(y_lat_test, y_lat_pred)\n",
        "lon_mse = mean_squared_error(y_lon_test, y_lon_pred)\n",
        "lon_r2 = r2_score(y_lon_test, y_lon_pred)\n",
        "\n",
        "print(\"Latitude Model Evaluation:\")\n",
        "print(f\"Mean Squared Error: {lat_mse}\")\n",
        "print(f\"R-squared: {lat_r2}\")\n",
        "\n",
        "print(\"\\nLongitude Model Evaluation:\")\n",
        "print(f\"Mean Squared Error: {lon_mse}\")\n",
        "print(f\"R-squared: {lon_r2}\")\n",
        "\n",
        "# Step 10: Save the trained models (optional)\n",
        "import joblib\n",
        "joblib.dump(latitude_pipeline, 'latitude_model.pkl')\n",
        "joblib.dump(longitude_pipeline, 'longitude_model.pkl')\n",
        "print(\"Trained models saved.\")\n",
        "\n",
        "# Step 11: Predict latitude and longitude for new data\n",
        "new_data = pd.DataFrame({\n",
        "    'HOUR': [15],         # Example hour\n",
        "    'WEATHERNAME': ['Clear'],  # Example weather\n",
        "    'FATALS': [2]         # Example fatalities\n",
        "})\n",
        "\n",
        "predicted_latitude = latitude_pipeline.predict(new_data)\n",
        "predicted_longitude = longitude_pipeline.predict(new_data)\n",
        "\n",
        "print(\"\\nPredicted Coordinates:\")\n",
        "print(f\"Latitude: {predicted_latitude[0]}\")\n",
        "print(f\"Longitude: {predicted_longitude[0]}\")\n"
      ],
      "metadata": {
        "id": "UJ-8H_CXWmtQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7225d0ad-42f9-4e67-880f-5e0d3bd9f638"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latitude Model Evaluation:\n",
            "Mean Squared Error: 39.02481202100808\n",
            "R-squared: 0.03366108061857176\n",
            "\n",
            "Longitude Model Evaluation:\n",
            "Mean Squared Error: 4561.010494950631\n",
            "R-squared: 0.023418425953329214\n",
            "Trained models saved.\n",
            "\n",
            "Predicted Coordinates:\n",
            "Latitude: 36.3331917801191\n",
            "Longitude: -90.46239571762254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wljqMxWQWmvQ"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}